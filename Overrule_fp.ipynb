{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "sys.path.append('./overlap-code')\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree, datasets\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, balanced_accuracy_score, precision_recall_curve, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from overrule.overrule import OverRule2Stage, OverRule\n",
    "from overrule.baselines import knn, marginal, propscore, svm\n",
    "from overrule.support import SVMSupportEstimator, SupportEstimator\n",
    "from overrule.overlap import SupportOverlapEstimator\n",
    "from overrule.ruleset import BCSRulesetEstimator, RulesetEstimator\n",
    "\n",
    "from utils import get_data, rule_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=0\n",
    "\n",
    "CNF=False\n",
    "VERBOSE=True\n",
    "\n",
    "ALPHA_s=0.99\n",
    "N_REF_MULT_s=0.3\n",
    "ALPHA_o=0.90\n",
    "N_REF_MULT_o=0\n",
    "\n",
    "LAMBDA0_s=0.1 # | 1e-05 fixed cost of term, the smaller the more rules you'll allow \n",
    "LAMBDA1_s=0.001 # cost per literal\n",
    "\n",
    "LAMBDA0_o=0.0000001 # fixed cost of term, the smaller the more rules you'll allow \n",
    "LAMBDA1_o=0.0000001 # cost per literal\n",
    "\n",
    "D=10  # Maximum extra rules per beam seach iteration\n",
    "K=10  # Maximum results returned during beam search\n",
    "B=28  # Width of Beam Search\n",
    "\n",
    "np.random.seed(SEED)\n",
    "w_eps = 1e-8\n",
    "CAT_COLS = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, a, y = get_data()\n",
    "X_df.shape\n",
    "\n",
    "X_df_sample = X_df.sample(frac=1, axis=1)\n",
    "# X_df_sample = X_df[X_df['v312_3'] == 1].sample(frac=1, axis=1)\n",
    "\n",
    "a_sample = a.iloc[X_df_sample.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5649, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cols = X_df_sample.columns\n",
    "\n",
    "base_estimator = LogisticRegression(solver='liblinear', max_iter=2000, C=0.005)\n",
    "learner = CalibratedClassifierCV(base_estimator=base_estimator, cv=5, method='isotonic')\n",
    "\n",
    "O = propscore.PropensityOverlapEstimator(estimator=learner)\n",
    "\n",
    "RS_s = BCSRulesetEstimator(n_ref_multiplier=N_REF_MULT_s, alpha=ALPHA_s, lambda0=LAMBDA0_s, lambda1=LAMBDA1_s, B=B, CNF=CNF, \n",
    "                           cat_cols=CAT_COLS, seed=SEED, K=K, D=D, binarizer='default')\n",
    "RS_o = BCSRulesetEstimator(n_ref_multiplier=N_REF_MULT_o, alpha=ALPHA_o, lambda0=LAMBDA0_o, lambda1=LAMBDA1_o, B=B, CNF=CNF, \n",
    "                           cat_cols=CAT_COLS, seed=SEED, binarizer='default')\n",
    "\n",
    "RS_s.fit(X_df_sample, a_sample)\n",
    "M = OverRule2Stage(O, RS_o, RS_s, refit_s=False)\n",
    "M.fit(X_df_sample, a_sample)\n",
    "\n",
    "rules1 = M.rules(as_str=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99, 0.9, 0.0001, 0.1, 1e-07)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALPHA_s, LAMBDA0_s, LAMBDA1_s, LAMBDA0_o, LAMBDA1_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = RS_s.predict(X_df_sample).mean()\n",
    "FPR = RS_s.relative_volume\n",
    "print(TPR, FPR)\n",
    "print(1/2 -  (FPR)/2 + TPR/2)\n",
    "print(M.score_vs_base(X_df_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(439492, 28)\n",
      "(5263, 6)\n"
     ]
    }
   ],
   "source": [
    "O2 = knn.KNNOverlapEstimator(k=30)\n",
    "\n",
    "RS_s = BCSRulesetEstimator(n_ref_multiplier=N_REF_MULT_s, alpha=ALPHA_s, lambda0=LAMBDA0_s, lambda1=LAMBDA1_s, B=B, CNF=CNF, \n",
    "                           cat_cols=CAT_COLS, seed=SEED, K=K, D=D, binarizer='tree')\n",
    "\n",
    "RS_o2 = BCSRulesetEstimator(n_ref_multiplier=N_REF_MULT_o, alpha=ALPHA_o, lambda0=LAMBDA0_o, lambda1=LAMBDA1_o, B=B, CNF=CNF, \n",
    "                           cat_cols=CAT_COLS, seed=SEED, binarizer='tree')\n",
    "\n",
    "RS_s.fit(X_df_sample, a_sample)\n",
    "M2 = OverRule2Stage(O2, RS_o2, RS_s, refit_s=False, bb_on_support=False)\n",
    "M2.fit(X_df_sample, a_sample)\n",
    "\n",
    "rules2 = M2.rules(as_str=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9316693220038945 0.25482720707721457\n",
      "0.83842105746334\n",
      "0.9634861407249466\n"
     ]
    }
   ],
   "source": [
    "TPR = RS_s.predict(X_df_sample).mean()\n",
    "FPR = RS_s.relative_volume\n",
    "print(TPR, FPR)\n",
    "print(1/2 -  (FPR)/2 + TPR/2)\n",
    "print(M2.score_vs_base(X_df_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  ((X_df[\"v191\"] <= 290545.000) & (X_df[\"v191\"] > -188796.000))'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(RS_o2.complexity())\n",
    "rule_str(RS_o2.rules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  (~X_df[\"v116_97\"].astype(bool) & ~X_df[\"v122_7\"].astype(bool) & (X_df[\"v201\"] > 0.500))| (X_df[\"v116_97\"].astype(bool) & X_df[\"v122_7\"].astype(bool) & (X_df[\"v201\"] > 0.500) & (X_df[\"v202\"] <= 2.500) & ~X_df[\"v513_3\"].astype(bool) & ~X_df[\"v602_4\"].astype(bool))'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(RS_s.complexity())\n",
    "rule_str(RS_s.rules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = rules1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of reference samples: {}'.format(RS_s.refSamples.shape[0]))\n",
    "print('Coverage of data points: %.3f, Requested >= %.3f' % (TPR, RS_s.M.alpha))\n",
    "print('Coverage of reference points: %.3f' % FPR)\n",
    "print('Rules: {}'.format(rules))\n",
    "print('Number of Rules: {}'.format(np.sum([len(rule) for rule in rules])))\n",
    "print('Number of Literals: {}'.format(np.sum([len(rule_) for rule in rules for rule_ in rule])))\n",
    "print('Complexity: {}'.format(RS_s.complexity()))\n",
    "print('AUC between rules and base estimator: {}'.format(M2.score_vs_base(X_df_sample)))\n",
    "\n",
    "import time\n",
    "outfile = open('results.txt', 'a+')\n",
    "\n",
    "\n",
    "outfile.write('Time: {}\\n'.format(time.time()))\n",
    "outfile.write('Binarizer: {}, {}, {}\\n'.format(RS_s.binarizer, RS_o.binarizer, RS_o2.binarizer))\n",
    "outfile.write('Params (knn): N_REF_MULT_s {}, N_REF_MULT_o {}, ALPHA_s {}, ALPHA_o {}, LAMBDA0_s {}, \\\n",
    "                LAMBDA1_s {}, LAMBDA0_o {}, LAMBDA1_o {}, B {}, CNF {}\\n\\n'.\n",
    "                    format(N_REF_MULT_s, N_REF_MULT_o, ALPHA_s, ALPHA_o, LAMBDA0_s, LAMBDA1_s, LAMBDA0_o, LAMBDA1_o, B, CNF))\n",
    "\n",
    "outfile.write('Number of reference samples: {}\\n'.format(RS_s.refSamples.shape[0]))\n",
    "outfile.write('Coverage of data points (TPR): %.3f, Requested >= %.3f\\n' % (TPR, RS_s.M.alpha))\n",
    "outfile.write('Coverage of reference points: (FPR) %.3f\\n' % FPR)\n",
    "outfile.write('Complexity: {}\\n'.format(RS_s.complexity()))\n",
    "outfile.write('Rules support: {}\\n\\n'.format(rule_str(rules1[0])))\n",
    "outfile.write('Rules stats support: {}\\n\\n'.format(rules_stats(RS_s.rules, X_df_sample))) \n",
    "\n",
    "\n",
    "outfile.write('Rules overlap (clr): {}\\n'.format(rule_str(rules1[1])))\n",
    "outfile.write('Rules stats overlap: {}\\n\\n'.format(rules_stats(RS_o.rules, X_df_sample))) \n",
    "outfile.write('Number of Rules: {}\\n'.format(np.sum([len(rule) for rule in rules1])))\n",
    "outfile.write('Number of Literals: {}\\n'.format(np.sum([len(rule_) for rule in rules1 for rule_ in rule])))\n",
    "outfile.write('AUC between rules and base estimator (propensity): {}\\n\\n'.format(M.score_vs_base(X_df_sample)))\n",
    "\n",
    "\n",
    "outfile.write('Rules overlap (knn): {}\\n'.format(rule_str(rules2[1])))\n",
    "outfile.write('Rules stats overlap: {}\\n\\n'.format(rules_stats(RS_o2.rules, X_df_sample))) \n",
    "outfile.write('Number of Rules: {}\\n'.format(np.sum([len(rule) for rule in rules2])))\n",
    "outfile.write('Number of Literals: {}\\n'.format(np.sum([len(rule_) for rule in rules2 for rule_ in rule])))\n",
    "outfile.write('AUC between rules and base estimator (propensity): {}\\n\\n'.format(M2.score_vs_base(X_df_sample)))\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exps.supp_synthetic.synth_utils import compliance\n",
    "\n",
    "def rules_stats(r_rules, df):\n",
    "\n",
    "    rules = r_rules(transform=lambda a,b: b, fmt='%.1f')\n",
    "    n_rules = float(len(rules))\n",
    "    n_rules_literals = float(np.sum([len(rule) for rule in rules]))\n",
    "\n",
    "    # Record more detailed rules information, e.g., proportion covered\n",
    "    D = pd.concat([\n",
    "        df,\n",
    "        pd.DataFrame(np.ones_like(a_sample), columns=['support_set'])\n",
    "        ], axis=1)\n",
    "    Cs = compliance(D, rules)\n",
    "\n",
    "    # This is everywhere, to be clear\n",
    "    I1 = np.where(D['support_set'].values==1)[0]\n",
    "\n",
    "    rule_stats = []\n",
    "    for i in range(len(rules)):\n",
    "        # Instances covered by rule\n",
    "        d = {}\n",
    "        d['rule'] = rules[i]\n",
    "        d['n_covered'] = float(Cs[i][:,I1].prod(0).sum())\n",
    "        d['p_covered'] = float(Cs[i][:,I1].prod(0).mean())\n",
    "        rule_stats.append(d)\n",
    "    return rule_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_res = []\n",
    "\n",
    "def find_hyp_config(hyp_res):\n",
    "    max_auc = 0\n",
    "    max_complexity = 0\n",
    "    max_hyp = {}\n",
    "    for res in hyp_res:\n",
    "        if res['auc'] > max_auc:\n",
    "            max_hyp = res\n",
    "            max_auc = res['auc']\n",
    "            max_complexity = res['complexity'][0] * res['complexity'][1]\n",
    "            \n",
    "    max_lambda1 = max_hyp['lambda1']\n",
    "    \n",
    "    candidates = []\n",
    "    for res in hyp_res:\n",
    "        if res['lambda1'] == max_lambda1:\n",
    "            \n",
    "            if res['complexity'][0] * res['complexity'][1] < max_complexity:\n",
    "                candidates.append(res)\n",
    "    \n",
    "    max_c_auc = 0\n",
    "    max_c = {}\n",
    "    for c in candidates:\n",
    "        if c['auc'] > max_c_auc:\n",
    "            max_c = c\n",
    "            max_c_auc = c['auc']\n",
    "        \n",
    "    return max_hyp, max_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'auc': 0.8951770825586689,\n",
       "  'complexity': (8, 59),\n",
       "  'lambda0': 1e-05,\n",
       "  'lambda1': 0.0001},\n",
       " {'auc': 0.8721470943239928,\n",
       "  'complexity': (3, 16),\n",
       "  'lambda0': 0.01,\n",
       "  'lambda1': 0.0001})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_hyp_config(hyp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('varencoding.txt', 'r') as f: \n",
    "    entire_doc = f.read()\n",
    "\n",
    "encoding = entire_doc.split(';')\n",
    "\n",
    "var_encoding = dict()\n",
    "for var in encoding:\n",
    "    var = var.strip()\n",
    "    splits = var.split('\\n')\n",
    "    k = splits[0].replace('define', '').strip()\n",
    "    vs = {}\n",
    "    for i in range(1, len(splits)):\n",
    "        v = splits[i].strip().split(\" \\\"\")\n",
    "        vs.update({v[0]: v[1].replace('\"', '')})\n",
    "    \n",
    "    var_encoding.update({k.lower(): vs})\n",
    "\n",
    "var_list = pd.read_csv('data/encoding.csv')\n",
    "\n",
    "\n",
    "def transcribe(rule_stats):\n",
    "    for single_rset in rule_stats:\n",
    "        single_rset_rule = single_rset['rule']\n",
    "        p_covered = round(single_rset['p_covered'] * 100, 3)\n",
    "        print(p_covered)\n",
    "        for i in range(len(single_rset_rule)):\n",
    "            rule = single_rset_rule[i]\n",
    "\n",
    "            if '_' in rule[0]:\n",
    "                var = rule[0].split(\"_\")[0]\n",
    "                level = rule[0].split(\"_\")[1]\n",
    "\n",
    "                var_str = var_list[var_list['var_name'] == var].label.values[0]\n",
    "                level_str = var_encoding[var][level]\n",
    "\n",
    "                rule_str = var_str + \" is \" + rule[1] + \" \\\"\" + level_str + \"\\\"\"\n",
    "                \n",
    "            else:\n",
    "\n",
    "                var = rule[0]\n",
    "                var_str = var_list[var_list['var_name'] == var].label.values[0]\n",
    "                rule_str = var_str + \" \" + rule[1] + \" \" +  str(round(rule[2]))\n",
    "            if i != len(single_rset_rule) - 1:\n",
    "                rule_str = rule_str + \" and\"\n",
    "                    \n",
    "#             print(\"& \" + rule_str + \" \\\\\\\\\")\n",
    "            print(rule_str)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_rule_stats = rules_stats(RS_s.rules, X_df_sample)\n",
    "knn_rule_stats = rules_stats(RS_o2.rules, X_df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support\n",
      "91.804\n",
      "Type of toilet facility is not \"Not a dejure resident\" and\n",
      "Household has: refrigerator is not \"Not a dejure resident\" and\n",
      "Total children ever born > 0\n",
      "\n",
      "\n",
      "1.363\n",
      "Type of toilet facility is  \"Not a dejure resident\" and\n",
      "Household has: refrigerator is  \"Not a dejure resident\" and\n",
      "Total children ever born > 0 and\n",
      "Sons at home <= 2 and\n",
      "Cohabitation duration (grouped) is not \"10-14\" and\n",
      "Fertility preference is not \"Sterilized (respondent or partner)\"\n",
      "\n",
      "\n",
      "overlap -knn\n",
      "98.973\n",
      "Wealth index factor score combined (5 decimals) <= 290545.0 and\n",
      "Wealth index factor score combined (5 decimals) > -188796.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"support\")\n",
    "transcribe(support_rule_stats)\n",
    "\n",
    "print(\"overlap -knn\")\n",
    "\n",
    "transcribe(knn_rule_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9316693220038945\n",
      "0.9897326960523987\n",
      "0.9235262878385555\n"
     ]
    }
   ],
   "source": [
    "support = X_df[(~X_df[\"v116_97\"].astype(bool) & ~X_df[\"v122_7\"].astype(bool) & (X_df[\"v201\"] > 0.500))| (X_df[\"v116_97\"].astype(bool) & X_df[\"v122_7\"].astype(bool) & (X_df[\"v201\"] > 0.500) & (X_df[\"v202\"] <= 2.500) & ~X_df[\"v513_3\"].astype(bool) & ~X_df[\"v602_4\"].astype(bool))]\n",
    "\n",
    "propensity = X_df[((X_df[\"v191\"] <= 290545.000) & (X_df[\"v191\"] > -188796.000))]\n",
    "\n",
    "print(len(support)/len(X_df))\n",
    "print(len(propensity)/len(X_df))\n",
    "\n",
    "X_overlap = pd.merge(support, propensity, how='inner')\n",
    "print(len(X_overlap) / len(X_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "x = []\n",
    "y = []\n",
    "v = []\n",
    "for r in results:\n",
    "    x.append(r['lambda0'])\n",
    "    y.append(r['lambda1'])\n",
    "    \n",
    "    v.append(r['auc'])\n",
    "\n",
    "plot = sns.scatterplot(x=[str(X) for X in x], y=[str(Y) for Y in y], hue=v, hue_order= [0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "leg = plot.get_legend()\n",
    "for t in leg.texts:\n",
    "    t.set_text(float(t.get_text()[:4]))\n",
    "\n",
    "plt.xlabel('λ0')\n",
    "plt.ylabel('λ1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".testenv",
   "language": "python",
   "name": ".testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
