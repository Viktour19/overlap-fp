{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "sys.path.append('./overlap-code')\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree, datasets\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, balanced_accuracy_score, precision_recall_curve, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from overrule.overrule import OverRule2Stage, OverRule\n",
    "from overrule.baselines import knn, marginal, propscore, svm\n",
    "from overrule.support import SVMSupportEstimator, SupportEstimator\n",
    "from overrule.overlap import SupportOverlapEstimator\n",
    "from overrule.ruleset import BCSRulesetEstimator, RulesetEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5649, 317)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "df = pd.read_csv('./data/fp_injectables_data.csv')\n",
    "\n",
    "y = df['outcome'] * 1\n",
    "a = df['treatment'] * 1\n",
    "X = df[df.columns[:-2]]\n",
    "X = X.apply(lambda x: x.fillna(x.median()),axis='rows')\n",
    "\n",
    "encoding = pd.read_csv('./data/encoding.csv')\n",
    "\n",
    "# Select and Encode ordinal features\n",
    "v = encoding[encoding['encoding'] == 'O']['var_name'].values\n",
    "enc = OrdinalEncoder()\n",
    "ord_data = enc.fit_transform(X[v])\n",
    "ord_features = v\n",
    "\n",
    "# Select the discrete features\n",
    "v = encoding[encoding['encoding'] == 'N']['var_name'].values\n",
    "dis_data = X[v].values\n",
    "dis_features = v\n",
    "\n",
    "# Select and Encode nominal features\n",
    "v = encoding[encoding['encoding'] == 'L']['var_name'].values\n",
    "j = X[v].astype(int)\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "nom_data = enc.fit_transform(j.astype(int))\n",
    "nom_features = enc.get_feature_names(v)\n",
    "\n",
    "\n",
    "# Combine all the features\n",
    "X_arr = np.concatenate((ord_data, nom_data.toarray(), dis_data), axis=1)\n",
    "features_names = np.concatenate((ord_features, nom_features, dis_features))\n",
    "\n",
    "print(X_arr.shape)\n",
    "X_df = pd.DataFrame(X_arr, columns=features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=0\n",
    "\n",
    "CNF=False\n",
    "VERBOSE=True\n",
    "\n",
    "ALPHA_s=0.95\n",
    "N_REF_MULT_s=1\n",
    "ALPHA_o=0.95\n",
    "N_REF_MULT_o=0\n",
    "\n",
    "LAMBDA0=0.9\n",
    "LAMBDA1=1e-3\n",
    "\n",
    "D=20  # Maximum extra rules per beam seach iteration\n",
    "K=20  # Maximum results returned during beam search\n",
    "B=300  # Width of Beam Search\n",
    "\n",
    "np.random.seed(SEED)\n",
    "w_eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Errors:\n",
    "# If i specify cat columns, and don't one-hot encode, the fit method runs out of resources\n",
    "# SolverError: Solver 'ECOS' failed. Try another solver or solve with verbose=True for more information. Try recentering the problem data around 0 and rescaling to reduce the dynamic range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_sample = X_df.sample(frac=0.3, axis=1)\n",
    "a_sample = a.iloc[X_df_sample.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5649, 95)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cols = X_df_sample.columns\n",
    "\n",
    "base_estimator = LogisticRegression(solver='liblinear', max_iter=2000, C=0.005)\n",
    "learner = CalibratedClassifierCV(base_estimator=base_estimator, cv=5, method='isotonic')\n",
    "\n",
    "O = propscore.PropensityOverlapEstimator(estimator=learner)\n",
    "\n",
    "RS_s = BCSRulesetEstimator(n_ref_multiplier=N_REF_MULT_s, alpha=ALPHA_s, lambda0=LAMBDA0, lambda1=LAMBDA1, B=B, CNF=CNF)\n",
    "RS_o = BCSRulesetEstimator(n_ref_multiplier=N_REF_MULT_o, alpha=ALPHA_o, lambda0=LAMBDA0, lambda1=LAMBDA1, B=B, CNF=CNF)\n",
    "\n",
    "M = OverRule2Stage(O, RS_o, RS_s)\n",
    "M.fit(X_df_sample, a_sample)\n",
    "\n",
    "rules = M.rules(as_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reference samples: 536655\n",
      "Coverage of data points: 0.993, Requested >= 0.950\n",
      "Coverage of reference points: 0.004\n",
      "Rules: ('  (not v532_4 ∧ not v626_6 ∧ not v128_14 ∧ not v127_96 ∧ not v161_95 ∧ not v116_42 ∧ [v206 <= 2.000] ∧ not v312_7)', '  ([v138 <= 1.000])\\n∨ ([v133 <= 10.000])\\n∨ (v605_5)')\n",
      "Complexity: (1, 8)\n",
      "AUC between rules and base estimator: 0.7018562335617978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of reference samples: {}'.format(RS_s.refSamples.shape[0]))\n",
    "print('Coverage of data points: %.3f, Requested >= %.3f' % (RS_s.predict(X_df_sample).mean(), RS_s.M.alpha))\n",
    "print('Coverage of reference points: %.3f' % RS_s.predict(RS_s.refSamples).mean())\n",
    "print('Rules: {}'.format(rules))\n",
    "print('Complexity: {}'.format(RS_s.complexity()))\n",
    "print('AUC between rules and base estimator: {}'.format(M.score_vs_base(X_df_sample)))\n",
    "\n",
    "import time\n",
    "outfile = open('metrics.txt', 'a+')\n",
    "\n",
    "\n",
    "outfile.write('Time: {}\\n'.format(time.time()))\n",
    "outfile.write('Params: N_REF_MULT_s {}, N_REF_MULT_o {}, ALPHA_s {}, ALPHA_o {}, LAMBDA0 {}, LAMBDA1 {}, B {}, CNF {}\\n'.\n",
    "                      format(N_REF_MULT_s, N_REF_MULT_o, ALPHA_s, ALPHA_o, LAMBDA0, LAMBDA1, B, CNF))\n",
    "outfile.write('Number of reference samples: {}\\n'.format(RS_s.refSamples.shape[0]))\n",
    "outfile.write('Coverage of data points (TPR): %.3f, Requested >= %.3f\\n' % (RS_s.predict(X_df_sample).mean(), RS_s.M.alpha))\n",
    "outfile.write('Coverage of reference points: (FPR) %.3f\\n' % RS_s.predict(RS_s.refSamples).mean())\n",
    "outfile.write('Rules: {}\\n'.format(rules))\n",
    "outfile.write('Complexity: {}\\n'.format(RS_s.complexity()))\n",
    "outfile.write('AUC between rules and base estimator: {}\\n'.format(M.score_vs_base(X_df_sample)))\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS_S = OverRule(alpha_s = 0.1, alpha_r =0.05, n_ref_multiplier=1., ruleset_kwargs={'lambda0':0.9, 'lambda1':0, 'B':300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = np.where(a_sample > 0)[0]\n",
    "N = np.where(a_sample == 0)[0]\n",
    "U = np.where(a_sample < 0)[0]\n",
    "\n",
    "\n",
    "nO = len(O)\n",
    "nN = len(N)\n",
    "nU = len(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1408, 4241, 0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nO, nN, nU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victora/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/victora/.local/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-a2e741f0a092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRS_S\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_df_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PositivityViolation/overlap-code/overrule/overrule.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, g)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_density\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PositivityViolation/overlap-code/overrule/ruleset.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, o)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;31m# Fit estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# Store reference volume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PositivityViolation/overlap-code/overrule/BCS/overlap_boolean_rule.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# MKO: We should always have overlap samples, and either background or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# non-overlap samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mnO\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnU\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnN\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# Initialize with empty and singleton conjunctions, i.e. X plus all-ones feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RS_S.fit(X_df_sample, a_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".testenv",
   "language": "python",
   "name": ".testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
